---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Yilie Huang is a Postdoctoral Research Scientist in the Department of Industrial Engineering and Operations Research at Columbia University, supervised by [Professor Xunyu Zhou](https://www.engineering.columbia.edu/faculty-staff/directory/xunyu-zhou). His research focuses on the intersection of reinforcement learning (RL), stochastic control, and financial engineering, with a particular interest in developing and analyzing continuous-time RL algorithms to optimize financial and control systems under uncertainty.

Huang completed his PhD in Industrial Engineering and Operations Research at Columbia University in 2024, advised by Professor Xunyu Zhou. He also earned an M.S. in Operations Research from Columbia University in 2018 and a B.S. in Mathematics and Applied Mathematics from Zhejiang University in 2017.

<!-- Key highlights of my work include:


-	Continuous-Time RL for Portfolio Selection: We propose a continuous-time actor-critic RL algorithm designed for mean-variance (MV) portfolio optimization. Its performance is theoretically guaranteed through the derivation of a sublinear regret bound in terms of the Sharpe ratio. Empirical evaluations using U.S. stock data from January 2000 to December 2019 show that the algorithm outperforms 15 well-established alternative strategies, particularly during bear markets.


-	Model-Free RL in Linear-Quadratic (LQ) Control: We study a model-free reinforcement learning approach for continuous-time LQ problems, where volatilities depend on both state and control variables. Two actor-critic algorithms are introduced: one employing deterministic exploration and the other adaptive exploration. Both achieve a regret bound of O(N^{3/4}) up to a logarithmic factor, with numerical comparisons showing superior performance over recent model-based methods. -->
